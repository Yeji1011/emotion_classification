{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2d64d0fb-e217-4be0-a551-35c5cfc067f4",
   "metadata": {},
   "source": [
    "# test 관련\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "34556569-5b87-44b6-ad7b-019ad82532ab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.pyplot._IonContext at 0x1d0a76052e0>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from __future__ import print_function, division\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.optim import lr_scheduler\n",
    "import torch.backends.cudnn as cudnn\n",
    "import numpy as np\n",
    "import torchvision\n",
    "from torchvision import datasets, models, transforms\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import os\n",
    "import copy\n",
    "\n",
    "cudnn.benchmark = True\n",
    "plt.ion()   # 대화형 모드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ac87ccf9-7c48-4717-8e32-3c8482a312c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------- GPU Working -------\n",
      "[Current GPU]: NVIDIA GeForce RTX 3090\n",
      "[PyTorch version]:  1.11.0\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    print(\"------- GPU Working -------\")\n",
    "    print(\"[Current GPU]: \" + str(torch.cuda.get_device_name(0)))\n",
    "else:\n",
    "    print(\"------- CPU Working -------\")\n",
    "print('[PyTorch version]: ', torch.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e8d319cf-670b-403d-9a32-a15a3c221e95",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size=1\n",
    "num_workers=8  #16안좋은듯"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4faec078-2950-4107-87a2-cf54655f91ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model loaded!\n"
     ]
    }
   ],
   "source": [
    "class_names = 7\n",
    "\n",
    "model=torchvision.models.resnet152(pretrained=True)\n",
    "\n",
    "# model_save_dir='C:\\\\Users\\\\yj\\\\Desktop/Task/Trasnfer_Learning/Resnet152/saved_model/F10/20220520_085918/F10_model.pth'\n",
    "model_save_dir='C:\\\\Users\\\\yj\\\\Desktop/Task/Trasnfer_Learning/Resnet152/Best_model_state/F11_model.pth'\n",
    "\n",
    "checkpoint = torch.load(model_save_dir)\n",
    "\n",
    "num_ftrs = model.fc.in_features #체크포인트 로드하기전에 동일하게(마지막단 노드수 7) 변경\n",
    "model.fc = torch.nn.Linear(num_ftrs, class_names) #(fc): Linear(in_features=2048, out_features=7, bias=True)\n",
    "model.to(device)\n",
    "\n",
    "model.load_state_dict(checkpoint)\n",
    "\n",
    "model.eval()\n",
    "print('Model loaded!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d8ee1f52-5b00-44c0-9277-0790f545c781",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_transforms = {\n",
    "    'train': transforms.Compose([\n",
    "        transforms.Resize((224, 224)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ]),\n",
    "    'valid': transforms.Compose([\n",
    "        transforms.Resize((224, 224)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ]),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2579755f-78cb-4d18-99e3-3ce9d987c16d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "74 ['F1', 'F10', 'F11', 'F12', 'F13', 'F14', 'F15', 'F16', 'F17', 'F18', 'F19', 'F2', 'F20', 'F21', 'F22', 'F23', 'F24', 'F25', 'F26', 'F27', 'F28', 'F29', 'F3', 'F30', 'F31', 'F32', 'F33', 'F34', 'F35', 'F36', 'F37', 'F4', 'F5', 'F6', 'F7', 'F8', 'F9', 'M1', 'M10', 'M11', 'M12', 'M13', 'M14', 'M15', 'M16', 'M17', 'M18', 'M19', 'M2', 'M20', 'M21', 'M22', 'M23', 'M24', 'M25', 'M26', 'M27', 'M28', 'M29', 'M3', 'M30', 'M31', 'M32', 'M33', 'M34', 'M35', 'M36', 'M37', 'M4', 'M5', 'M6', 'M7', 'M8', 'M9']\n"
     ]
    }
   ],
   "source": [
    "datasetDirectory_path = 'C:\\\\Users\\\\yj\\\\Desktop\\\\Task\\\\Trasnfer_Learning\\\\dataset_per_sub'#sub별 정서이미지폴더 리스트(폴더명)\n",
    "\n",
    "# datasetDirectory_path=os.path.join(current_dir, data_dir)\n",
    "datasetDirectory_list = os.listdir(datasetDirectory_path)\n",
    "print(len(datasetDirectory_list), datasetDirectory_list) #['F1', ~ 'M37']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4478a1a4-3bee-4b0d-8c3a-56208d42aea8",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataloaders_set = []\n",
    "dataset_sizes_set = []\n",
    "\n",
    "for i in range(len(datasetDirectory_list)):\n",
    "    sub = datasetDirectory_list[i]\n",
    "\n",
    "    path = {x: os.path.join(datasetDirectory_path, datasetDirectory_list[i], x)  for x in ['train', 'valid']} \n",
    "\n",
    "    image_datasets = {x: datasets.ImageFolder(path[x],\n",
    "                                          data_transforms[x])\n",
    "                                    for x in ['train', 'valid']}\n",
    "    # print('image_datasets========== ', image_datasets)\n",
    "    \n",
    "    dataloaders = { 'train' : torch.utils.data.DataLoader(image_datasets['train'], batch_size=batch_size,\n",
    "                                             shuffle=True, num_workers=num_workers, pin_memory=True),\n",
    "                'valid' : torch.utils.data.DataLoader(image_datasets['valid'], batch_size=4,\n",
    "                                             shuffle=False, num_workers=num_workers, pin_memory=True) }\n",
    "    # print('dataloaders=========', dataloaders)\n",
    "    dataloaders_set.append(dataloaders)\n",
    "    \n",
    "    dataset_sizes = {x: len(image_datasets[x]) for x in ['train', 'valid']}\n",
    "    dataset_sizes_set.append(dataset_sizes)\n",
    "    \n",
    "# print('dataloaders_set', dataloaders_set)\n",
    "# print()\n",
    "# print('dataset_sizes', dataset_sizes)\n",
    "# print('dataset_sizes_set', dataset_sizes_set)\n",
    "# print(dataloaders_set)\n",
    "# dataset_sizes\n",
    "# dataset_sizes_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5e5cea56-dfc9-41f8-a306-c02efb4f75d6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datasetDirectory_list.index('F11')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2bdcc9d9-707d-4c76-b89d-9bf7d2e03bba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "label: tensor([0, 1, 2, 3], device='cuda:0')\n",
      "preds: tensor([0, 1, 2, 3], device='cuda:0')\n",
      "label: tensor([4, 5, 6], device='cuda:0')\n",
      "preds: tensor([4, 5, 6], device='cuda:0')\n",
      "Test accuracy: 1.0000\n"
     ]
    }
   ],
   "source": [
    "import torch.nn.functional as F\n",
    "from tqdm import tqdm\n",
    "\n",
    "model.eval()\n",
    "\n",
    "images_so_far = 0\n",
    "\n",
    "total_loss = 0\n",
    "total_len = 0\n",
    "total_correct = 0\n",
    "\n",
    "with torch.no_grad():\n",
    "    for i, (sample, label) in enumerate(dataloaders_set[2]['valid']):\n",
    "        sample = sample.to(device)\n",
    "        # print(type(inputs))\n",
    "        # print(inputs.size()) #torch.Size([4, 3, 224, 224])\n",
    "        # print(inputs.size()[0]) # 4\n",
    "        label = label.to(device)\n",
    "        print('label:', label)\n",
    "        labels = label.clone().detach()  #labels: tensor([0, 1, 2, 3], device='cuda:0')\n",
    "        # print('labels:', labels)\n",
    "        \n",
    "        outputs = model(sample) # 배치4개씩 [7차원]의 텐서 나옴\n",
    "        # print('outputs', outputs)\n",
    "        _, preds = torch.max(outputs, 1) #_수치높은값, pred: 수치높은값의 인덱스 tensor([0, 1, 2, 3] #preds tensor([0, 1, 4, 3], device='cuda:0')\n",
    "        print('preds:', preds)\n",
    "        if list(preds) != list(labels):\n",
    "            for p in range(len(preds)):\n",
    "                print('Not predictd: pred {} label {}'.format(preds[p], labels[p]))\n",
    "        \n",
    "        correct = preds.eq(labels) # pred랑 label이랑 같으면 true반환 #correct tensor([ True,  True, False,  True], device='cuda:0')\n",
    "           # print('prediect: {}, label: {}'.format(preds, labels))\n",
    "        \n",
    "        total_correct += correct.sum().item()  #true(맞힌)개수      \n",
    "        total_len += len(labels) # labels개수=배치 수\n",
    "    print('Test accuracy: {:.4f}'.format(total_correct / total_len))      \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90dc3181-e13d-4f10-8b0e-65f0c84078a1",
   "metadata": {},
   "source": [
    "# RoBERTa 테스트 코드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97e1ea87-ba1e-45f9-9b18-8a5d203c2e03",
   "metadata": {},
   "outputs": [],
   "source": [
    "#20211126_121016\n",
    "\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\"\n",
    "\n",
    "\n",
    "import torch\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(device)\n",
    "print('Available device : ', torch.cuda.device_count())\n",
    "print('Current cuda device :', torch.cuda.current_device())\n",
    "print(torch.cuda.get_device_name(device))\n",
    "\n",
    "\n",
    "# Setting parameters\n",
    "batch_size = 200\n",
    "num_label = 2\n",
    "learning_rate = 1e-5\n",
    "max_grad_norm = 1\n",
    "# epochs = 2\n",
    "num_workers = 8\n",
    "# max_len = 512\n",
    "\n",
    "\n",
    "\n",
    "import time\n",
    "start_time = time.time()\n",
    "\n",
    "from transformers import BertTokenizer, RobertaTokenizer, RobertaForSequenceClassification\n",
    "import torch\n",
    "\n",
    "config = 'klue/roberta-large'\n",
    "tokenizer = BertTokenizer.from_pretrained(config)\n",
    "model = RobertaForSequenceClassification.from_pretrained(config, num_labels=num_label)\n",
    "model.to(device)\n",
    "\n",
    "\n",
    "model_save_dir='/home/yeji/standard/model/chitchat_classification/chitchat_classification/Mix_5sentences3/experiment_dataset2/saved_model/epoch_1.pt'\n",
    "learning_rate = 1e-5\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=learning_rate)\n",
    "checkpoint = torch.load(model_save_dir)\n",
    "\n",
    "# 원래 module. 없어야됨\n",
    "# 근데 생겨서 지움\n",
    "new_checkpoint = { k.replace('module.','') if 'module.' in k else k:v for k,v in checkpoint['model_state_dict'].items()}\n",
    "\n",
    "model.load_state_dict(new_checkpoint)#checkpoint['model_state_dict'])\n",
    "optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "epoch = checkpoint['epoch']\n",
    "# model.to(device)\n",
    "\n",
    "model.eval()\n",
    "print('Model loaded!')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf474668-67e0-4e13-8c2d-c5f1f88a7176",
   "metadata": {},
   "source": [
    "# ========================================================================="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8f49ca9e-3ade-4740-b84e-15a82dc5897b",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "path='C:\\\\Users\\\\yj\\\\Desktop/새 폴더/Dataset/dataset_per_sub'\n",
    "subject_list = os.listdir(path)\n",
    "# subject"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6644c220-49bc-4425-bf27-c0ac1f6a95dc",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "test_transform = torchvision.transforms.Compose([\n",
    "                                transforms.Resize((224, 224)),\n",
    "                                transforms.ToTensor(),\n",
    "                                transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "                                ])\n",
    "\n",
    "test_loader_set = []\n",
    "\n",
    "for one_sub in subject:\n",
    "    # try:\n",
    "    test_path= 'C:\\\\Users\\\\yj\\\\Desktop/새 폴더/Dataset/dataset_per_sub\\\\'  +  '{}\\\\test'.format(one_sub)\n",
    "    test_dataset = torchvision.datasets.ImageFolder(test_path, transform=test_transform)\n",
    "    test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=1, shuffle=False, num_workers=num_workers)\n",
    "    test_loader_set.append(test_loader)\n",
    "    # except:\n",
    "    #     pass\n",
    "    # break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0478cdd5-67a3-4320-b1af-a0c780273b6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_checkpoint(subject):\n",
    "\n",
    "    class_names = 7\n",
    "    learning_rate =0.1 #1e-5(X)\n",
    "\n",
    "    model=torchvision.models.resnet152(pretrained=True)\n",
    "\n",
    "    num_ftrs = model.fc.in_features \n",
    "    model.fc = torch.nn.Linear(num_ftrs, class_names) #(fc): Linear(in_features=2048, out_features=7, bias=True)\n",
    "    model.to(device)\n",
    "\n",
    "    model_save_dir='C:\\\\Users\\\\yj\\\\Desktop/Task/Trasnfer_Learning/Resnet152/saved_model/20220602_235407/' + '{}.pt'.format(subject)\n",
    "    # print(model_save_dir) #C:\\Users\\yj\\Desktop/Task/Trasnfer_Learning/Resnet152/saved_model/20220602_235407/F1.pt\n",
    "    optimizer = torch.optim.SGD(model.fc.parameters(), lr=learning_rate, momentum=0.9,\n",
    "                                     weight_decay=0.0001)\n",
    "    checkpoint = torch.load(model_save_dir)\n",
    "\n",
    "    model.load_state_dict(checkpoint['model_state_dict'])#checkpoint['model_state_dict'])\n",
    "    optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "    epoch = checkpoint['epoch']\n",
    "\n",
    "    model.eval()\n",
    "    # print('Model loaded!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "60e17254-2a17-4ae5-a529-68220c9ee65d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from openpyxl import Workbook\n",
    "workbook = Workbook( )#workbook 생성하기(1개의 시트가 생성된 상태)\n",
    "sheet = workbook.active #현재 workbook의 활성화 된 Sheet 가져오기\n",
    "sheet.title = \"정확도\" #해당 sheet의 sheet명 변경하기\n",
    "\n",
    "def test(subject, test_loader):\n",
    "    model.eval()\n",
    "\n",
    "    total_loss = 0\n",
    "    total_len = 0\n",
    "    total_correct = 0\n",
    "\n",
    "    for batch_sample, batch_label in test_loader:\n",
    "\n",
    "        sample = batch_sample.to(device)\n",
    "        label = batch_label.to(device)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            output = model.forward(sample) \n",
    "        # loss = loss_func(output, label)     \n",
    "\n",
    "        _, output_index = torch.max(output, 1)   \n",
    "        preds = output_index\n",
    "        # print('preds:', preds)\n",
    "        # if list(preds) != list(labels):\n",
    "        #     for p in range(len(preds)):\n",
    "        #         print('Not predictd: pred {} label {}'.format(preds[p], labels[p]))        \n",
    "        correct = preds.eq(label)   #1배치에 맞힌 갯수     \n",
    "        # print('correct', correct)\n",
    "        total_correct += correct.sum().item()  #1배치에 맞힌 개수 계속 더함        \n",
    "        # print('total_correct', total_correct)\n",
    "        total_len += len(label)      #1배치 갯수 계속 더함\n",
    "        # print('total_len', total_len)\n",
    "\n",
    "        test_accuracy = total_correct / total_len #이시점까지(에폴당) 누적된(배치마다 계속 맞힌 갯수 더한) 정확도\n",
    "        # print('test_accuracy', test_accuracy)\n",
    "    # print('{}/{}  Test accuracy: {:.4f}'.format(epoch + 1, epochs, test_accuracy)) #(에폭당) 전체데이터셋에 대한 정확도 #마지막 배치(앞에서부터 끝까지 누적됨)정확도랑 같음\n",
    "    print('{} Test accuracy: {:.4f}'.format(subject, test_accuracy)) \n",
    "    # write_ws = write_wb.active #디폴트 시트 선택 #현재 workbook의 활성화 된 Sheet 가져오기\n",
    "    \n",
    "    # cell에 직접 데이터 입력하기\n",
    "    sheet['A1'] = \"Subject\"\n",
    "    # sheet['B1'] = \"\"\n",
    "    \n",
    "    sheet.append(['{}'.format(subject),\n",
    "                     'Test accuracy:',\n",
    "                     '{:.4f}'.format(test_accuracy)])# row 단위로 데이터 입력하기\n",
    "    # write_ws.append(['{}'.format(subject),\n",
    "    #                  'Test accuracy:',\n",
    "    #                  '{:.4f}'.format(test_accuracy)])# row 단위로 데이터 입력하기\n",
    "\n",
    "    # write_ws.append(['{} Test accuracy: {:.4f}'.format(subject, test_accuracy)])\n",
    "    workbook.save('./Test_Accuracy.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "a56d0862-d1a9-48d3-9b67-6dd17ac24483",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 Test accuracy: 1.0000\n",
      "F10 Test accuracy: 0.8571\n",
      "F11 Test accuracy: 1.0000\n",
      "F12 Test accuracy: 1.0000\n",
      "F13 Test accuracy: 1.0000\n",
      "F14 Test accuracy: 1.0000\n",
      "F15 Test accuracy: 1.0000\n",
      "F16 Test accuracy: 1.0000\n",
      "F17 Test accuracy: 1.0000\n",
      "F18 Test accuracy: 1.0000\n",
      "F19 Test accuracy: 1.0000\n",
      "F2 Test accuracy: 1.0000\n",
      "F20 Test accuracy: 1.0000\n",
      "F21 Test accuracy: 1.0000\n",
      "F22 Test accuracy: 1.0000\n",
      "F23 Test accuracy: 1.0000\n",
      "F24 Test accuracy: 1.0000\n",
      "F25 Test accuracy: 1.0000\n",
      "F26 Test accuracy: 1.0000\n",
      "F27 Test accuracy: 1.0000\n",
      "F28 Test accuracy: 1.0000\n",
      "F29 Test accuracy: 1.0000\n",
      "F3 Test accuracy: 1.0000\n",
      "F30 Test accuracy: 1.0000\n",
      "F31 Test accuracy: 1.0000\n",
      "F32 Test accuracy: 1.0000\n",
      "F33 Test accuracy: 1.0000\n",
      "F34 Test accuracy: 1.0000\n",
      "F35 Test accuracy: 1.0000\n",
      "F36 Test accuracy: 1.0000\n",
      "F37 Test accuracy: 1.0000\n",
      "F4 Test accuracy: 1.0000\n",
      "F5 Test accuracy: 1.0000\n",
      "F6 Test accuracy: 0.1429\n",
      "F7 Test accuracy: 1.0000\n",
      "F8 Test accuracy: 1.0000\n",
      "F9 Test accuracy: 1.0000\n",
      "M1 Test accuracy: 1.0000\n",
      "M10 Test accuracy: 1.0000\n",
      "M11 Test accuracy: 1.0000\n",
      "M12 Test accuracy: 1.0000\n",
      "M13 Test accuracy: 1.0000\n",
      "M14 Test accuracy: 1.0000\n",
      "M15 Test accuracy: 1.0000\n",
      "M16 Test accuracy: 1.0000\n",
      "M17 Test accuracy: 1.0000\n",
      "M18 Test accuracy: 1.0000\n",
      "M19 Test accuracy: 1.0000\n",
      "M2 Test accuracy: 1.0000\n",
      "M20 Test accuracy: 1.0000\n",
      "M21 Test accuracy: 1.0000\n",
      "M22 Test accuracy: 1.0000\n",
      "M23 Test accuracy: 1.0000\n",
      "M24 Test accuracy: 0.8571\n",
      "M25 Test accuracy: 1.0000\n",
      "M26 Test accuracy: 1.0000\n",
      "M27 Test accuracy: 1.0000\n",
      "M28 Test accuracy: 1.0000\n",
      "M29 Test accuracy: 1.0000\n",
      "M3 Test accuracy: 1.0000\n",
      "M30 Test accuracy: 1.0000\n",
      "M31 Test accuracy: 1.0000\n",
      "M32 Test accuracy: 1.0000\n",
      "M33 Test accuracy: 1.0000\n",
      "M34 Test accuracy: 1.0000\n",
      "M35 Test accuracy: 1.0000\n",
      "M36 Test accuracy: 1.0000\n",
      "M37 Test accuracy: 1.0000\n",
      "M4 Test accuracy: 1.0000\n",
      "M5 Test accuracy: 1.0000\n",
      "M6 Test accuracy: 1.0000\n",
      "M7 Test accuracy: 1.0000\n",
      "M8 Test accuracy: 1.0000\n",
      "M9 Test accuracy: 1.0000\n"
     ]
    }
   ],
   "source": [
    "for one_subject, test_loader in zip(subject_list, test_loader_set):\n",
    "    # print(one_subject, test_loader) #F1 <torch.utils.data.dataloader.DataLoader object at 0x00000207957697F0>\n",
    "#     \n",
    "    load_checkpoint(subject=one_subject)\n",
    "    test(subject=one_subject, test_loader=test_loader)\n",
    "    # break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b457c84f-3ec1-46c1-890b-6ce63548c782",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_checkpoint(final_save_dir): \n",
    "    \n",
    "    if os.path.exists(final_save_dir):        \n",
    "\n",
    "        checkpoint = torch.load(final_save_dir)\n",
    "        \n",
    "        epoch = checkpoint['epoch']\n",
    "        model.load_state_dict(checkpoint['model_state_dict'])\n",
    "        optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "        # print(\"=> loading checkpoint\")      \n",
    "    \n",
    "    else:\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a905d885-26d5-43d5-afcc-0d8d1375ecce",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
